{
  "features_dim": 2048,
  "max_stages": 4,
  "batch_size": 4,
  "json_file_path": "/data/TalkingLatents/data/dataset/stellar_evolution_results_complete.json",
  "checkpoint_path": "/data/TalkingLatents/checkpoints/state_space_llm_alpha_10.0_beta_1.0_gamma_1.0_freeze_encoder_only.pth",
  "learning_rate": 1e-4,
  "weight_decay": 0.01,
  "num_epochs": 1000,
  "max_sequence_length": 512,
  "encoder_only_epochs": 5,
  "encoder_lr_multiplier": 2.0,
  "alpha": 10.0,
  "beta": 1.0,
  "gamma": 1.0,
  "load_checkpoints": 0,
  "train": 1,
  "lora_params": {
    "freeze_strategy": "lora",
    "lora_start_epoch": 3,
    "lora_lr_multiplier": 1.0,
    "lora_rank": 8,
    "lora_alpha": 8.0,
    "lora_dropout": 0,
    "lora_target_modules": [
    "base_model.layers.*.attention.wq",
    "base_model.layers.*.attention.wk", 
    "base_model.layers.*.attention.wv",
    "base_model.layers.*.attention.wo",
    "base_model.layers.*.feed_forward.w1",
    "base_model.layers.*.feed_forward.w2",
    "base_model.layers.*.feed_forward.w3",
    
    "module.base_model.layers.*.attention.wq",
    "module.base_model.layers.*.attention.wk",
    "module.base_model.layers.*.attention.wv", 
    "module.base_model.layers.*.attention.wo",
    "module.base_model.layers.*.feed_forward.w1",
    "module.base_model.layers.*.feed_forward.w2",
    "module.base_model.layers.*.feed_forward.w3"
    
    ]
  }
}